library(rstan)
model <- stan_model('D:/md.stan')
library(rstan)
model <- stan_model('D:/md.stan')
library(rstan)
model <- stan_model('D:/md.stan')
library(rstan)
model <- stan_model('D:/md.stan')
library(rstan)
model <- stan_model('D:/md.stan')
library(rstan)
model <- stan_model('D:/md.stan')
library(rstan)
model <- stan_model('D:/md.stan')
library(rstan)
model <- stan_model('D:/md.stan')
library(rstan)
version
library(tidyverse)
mm <- stan_model('D:/md.stan')
mm <- stan_model('D:/md.stan')
uninstall.packages('msm')
uninstall.packages('rstan')
remove.packages('rstan')
install.packages('rstan')
library(rstan)
mm <- stan_model('D:/md.stan')
library(rstan)
ms <- stan_model('D:/md.stan')
library(rstan)
ms <- stan_model('D:/md.stan')
x <- rnormal(100, 0, 10)
ms <- stan_model('D:/md.stan')
x <- rnormal(100, 0, 10)
x <- rnorm(100, 0, 10)
df <- list(x = x, N = 100)
?sampling
a <- sampling(ms,
df,
chains = 1,
iter = 200)
a <- sampling(ms,
df,
chains = 1,
iter = 1000)
a <- sampling(ms,
df,
chains = 4,
iter = 2000)
a
install.packages('parallel')
library(parallel)
detectCores()
a <- sampling(ms,
df,
chains = 2,
cores = 2
iter = 1000)
a <- sampling(ms,
df,
chains = 2,
cores = 2,
iter = 1000)
a <- sampling(ms,
df,
chains = 2,
cores = 2,
iter = 2000)
install.packages('rstudioapi')
a <- sampling(ms,
df,
chains = 2,
cores = 2,
iter = 2000)
a
a <- sampling(ms,
df,
chains = 2,
cores = 2,
iter = 20000)
start <- Sys.time()
a <- sampling(ms,
df,
chains = 2,
cores = 2,
iter = 200000)
end <- Sys.time()
end - start
start <- Sys.time()
a <- sampling(ms,
df,
chains = 2,
cores = 2,
iter = 200000)
end <- Sys.time()
end - start
start <- Sys.time()
a <- sampling(ms,
df,
chains = 2,
cores = 2,
iter = 200000)
end <- Sys.time()
end - start
start <- Sys.time()
a <- sampling(ms,
df,
chains = 2,
cores = 1,
iter = 200000)
end <- Sys.time()
end - start
start <- Sys.time()
a <- sampling(ms,
df,
chains = 2,
cores = 1,
iter = 200000)
end <- Sys.time()
end - start
x <- rnorm(10000, 0, 10)
N <- 10000
N <- 10000
x <- rnorm(N, 0, 10)
df <- list(N = N, x = x)
df <- list(N = N, x = x)
start <- Sys.time()
a <- sampling(ms,
df,
chains = 2,
cores = 1,
iter = 20000)
end <- Sys.time()
end - start
N <- 100000
x <- rnorm(N, 0, 10)
df <- list(N = N, x = x)
start <- Sys.time()
a <- sampling(ms,
df,
chains = 2,
cores = 1,
iter = 20000)
end <- Sys.time()
end - start
start <- Sys.time()
a <- sampling(ms,
df,
chains = 2,
cores = 2,
iter = 20000)
end <- Sys.time()
end - start
N <- 100000
x <- rnorm(N, 0, 10)
df <- list(N = N, x = x)
start <- Sys.time()
a <- sampling(ms,
df,
chains = 2,
cores = 2,
iter = 20000)
end <- Sys.time()
end - start
N <- 100000
x <- rnorm(N, 0, 10)
df <- list(N = N, x = x)
start <- Sys.time()
a <- sampling(ms,
df,
chains = 2,
cores = 4,
iter = 20000)
end <- Sys.time()
end - start
N <- 100000
x <- rnorm(N, 0, 10)
df <- list(N = N, x = x)
start <- Sys.time()
a <- sampling(ms,
df,
chains = 2,
cores = 4,
iter = 20000)
end <- Sys.time()
end - start
start <- Sys.time()
a <- sampling(ms,
df,
chains = 2,
cores = 8,
iter = 20000)
end <- Sys.time()
end - start
N <- 100000
x <- rnorm(N, 0, 10)
df <- list(N = N, x = x)
start <- Sys.time()
a <- sampling(ms,
df,
chains = 4,
cores = 8,
iter = 20000)
end <- Sys.time()
end - start
library(cobalt)
?bal.tab
dirname(rstudioapi::getSourceEditorContext()$path)
#### Sample size calculation ####
# Preparation ----
rm(list = ls())
setwd('NeCTAR/sampleSize')
setwd('D:/github')
setwd('NeCTAR/sampleSize')
# Library ----
# install.packages("brms", repos = "https://cloud.r-project.org")
library(brms)
library(doParallel)
library(magrittr)
library(tidyverse)
N <- c(2:7)*100
p1 <- c(3:8)/20
delta <- c(2:6)/50
n_sampling <- 5   # number of sampling in estimation
N
p1
p1 <- c(3:10)/20
p1
p1 <- c(1:5)/10
p1
delta <- c(2:6)/50
delta
N <- c(3:8)*100
p1 <- c(1:5)/10
delta <- c(2:6)/50
n_sampling <- 10   # number of sampling in estimation
# Library ----
# install.packages("brms", repos = "https://cloud.r-project.org")
library(brms)
library(doParallel)
library(magrittr)
library(tidyverse)
# Function ----
recruitSim <- function(N = N[1], p1 = p1[1], delta = delta[1]){
# assume 10 blocks, uneven distribution
block <- rbinom(N, 10, 2:8/10) + 1
block <- data.frame(block = block)
block %<>% arrange(block) %>%
group_by(block) %>%
summarise(count = n())
recruit <- blockList %>% left_join(block, by = 'block') %>%
filter(!is.na(count), sequence <= count) %>%
mutate(probE = ifelse(allocation == 1,
p1 - delta,
p1)) %>%
rowwise %>%
mutate(outcome = rbinom(1, 1, probE))
return(recruit)
}
func <- function(index = index, scenario = scenario){
for(i in 1:nrow(scenario)){
dfSim <- recruitSim(N = scenario$N[i],
p1 = scenario$p1[i],
delta = scenario$delta[i])
fit <- brm(data = dfSim,
outcome ~ allocation,
family  = bernoulli(link = "logit"),
prior = prior(normal(0, 10), class = b),
chains = 4,
cores = 4)
coef <- fixef(fit)
scenario[i, c('est', 's.e.', 'QL', 'QU')] <- coef[2,]
scenario$index <- index
}
return(scenario)
}
# Load block randomization list ----
blockList <- read.csv('blockList.csv') %>%
rename(block = pattern) %>%
mutate(allocation = recode(allocation,
'colistin' = 1,
'saline' = 0))
View(blockList)
runif(10, min = 0, max = 1)
comp <- runif(10, min = 0, max = 1)
sum(comp)
comp <- comp/sum(comp)
comp[order(comp)]
scenario <- expand.grid(N = N, p1 = p1, delta = delta)
scenario
150*3
450/60
N
N <- c(3:7)*100 + 50
N
p1 <- c(1:5)/10
p1
0.15*4
(0:3)*0.15
N <- c(3:7)*100 + 50
p1 <- c(1:4)*0.1
p1
delta <- c(2:6)/50
delta
0.025*(3:6)
0.025*(2:6)
delta <- c(2:6)/40
delta
n_sampling <- 10   # number of sampling in estimation
scenario <- expand.grid(N = N, p1 = p1, delta = delta)
3*100
# Library ----
# install.packages("brms", repos = "https://cloud.r-project.org")
library(brms)
library(doParallel)
library(magrittr)
library(tidyverse)
# Different scenarios ----
# N <- (1:20)*50
# p1 <- c(3:10)/20
# delta <- c(1:15)/100
N <- c(3:7)*100 + 50
p1 <- c(1:5)*0.1
delta <- c(2:6)/40
n_sampling <- 50   # number of sampling in estimation
# Function ----
recruitSim <- function(N = N[1], p1 = p1[1], delta = delta[1]){
# assume 10 blocks, uneven distribution
block <- rbinom(N, 10, 2:8/10) + 1
block <- data.frame(block = block)
block %<>% arrange(block) %>%
group_by(block) %>%
summarise(count = n())
recruit <- blockList %>% left_join(block, by = 'block') %>%
filter(!is.na(count), sequence <= count) %>%
mutate(probE = ifelse(allocation == 1,
p1 - delta,
p1)) %>%
rowwise %>%
mutate(outcome = rbinom(1, 1, probE))
return(recruit)
}
func <- function(index = index, scenario = scenario){
for(i in 1:nrow(scenario)){
dfSim <- recruitSim(N = scenario$N[i],
p1 = scenario$p1[i],
delta = scenario$delta[i])
fit <- brm(data = dfSim,
outcome ~ allocation,
family  = bernoulli(link = "logit"),
prior = prior(normal(0, 10), class = b),
chains = 4,
cores = 4)
coef <- fixef(fit)
scenario[i, c('est', 's.e.', 'QL', 'QU')] <- coef[2,]
scenario$index <- index
}
return(scenario)
}
# Load block randomization list ----
blockList <- read.csv('blockList.csv') %>%
rename(block = pattern) %>%
mutate(allocation = recode(allocation,
'colistin' = 1,
'saline' = 0))
# Loop ----
scenario <- expand.grid(N = N, p1 = p1, delta = delta)
index <- split(1:n_sampling, 1:n_sampling)
index
block <- rbinom(N, 10, 2:8/10) + 1
block
N
N <- 350
block <- rbinom(N, 10, 2:8/10) + 1
block
table(block)
comp <- runif(10, min = 0, max = 1)
comp <- comp/sum(comp)
comp
# assume 10 blocks, uneven distribution
n_block <- 10
comp <- runif(n_block, min = 0, max = 1)
comp <- comp/sum(comp)
comp
sample(20, 1:10, comp)
sample(1:10, size = 20, prob = comp)
sample(1:10, size = 20, replace = T prob = comp)
sample(1:10, size = 20, replace = T, prob = comp)
sample(1:10, size = 500, replace = T, prob = comp)
a <- sample(1:10, size = 500, replace = T, prob = comp)
table(a)
comp
sum(comp)
a/500
table(a)/500
comp
index
index
5*40
10*30
300*17
40*19
